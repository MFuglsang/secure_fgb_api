{"version":3,"sources":["../../../../src/ts/http-reader.ts"],"sourcesContent":["import { Repeater } from '@repeaterjs/repeater';\nimport * as flatbuffers from 'flatbuffers';\n\nimport Config from './config.js';\nimport { magicbytes, SIZE_PREFIX_LEN } from './constants.js';\nimport { Feature } from './flat-geobuf/feature.js';\nimport type { HeaderMeta } from './header-meta.js';\nimport { fromByteBuffer } from './header-meta.js';\nimport { calcTreeSize, DEFAULT_NODE_SIZE, NODE_ITEM_BYTE_LEN, type Rect, streamSearch } from './packedrtree.js';\n\ninterface FeatureWithId {\n    id: number;\n    feature: Feature;\n}\n\nexport class HttpReader {\n    private headerClient: BufferedHttpRangeClient;\n    public header: HeaderMeta;\n    private headerLength: number;\n    private indexLength: number;\n    private nocache: boolean;\n    private headers: HeadersInit;\n\n    constructor(\n        headerClient: BufferedHttpRangeClient,\n        header: HeaderMeta,\n        headerLength: number,\n        indexLength: number,\n        nocache: boolean,\n        headers: HeadersInit = {},\n    ) {\n        this.headerClient = headerClient;\n        this.header = header;\n        this.headerLength = headerLength;\n        this.indexLength = indexLength;\n        this.nocache = nocache;\n        this.headers = headers;\n    }\n\n    // Fetch the header, preparing the reader to read Feature data.\n    //\n    // and potentially some opportunistic fetching of the index.\n    static async open(url: string, nocache: boolean, headers: HeadersInit = {}): Promise<HttpReader> {\n        // In reality, the header is probably less than half this size, but\n        // better to overshoot and fetch an extra kb rather than have to issue\n        // a second request.\n        const assumedHeaderLength = 2024;\n\n        const headerClient = new BufferedHttpRangeClient(url, nocache, headers);\n\n        // Immediately following the header is the optional spatial index, we deliberately fetch\n        // a small part of that to skip subsequent requests.\n        const assumedIndexLength = (() => {\n            // The actual branching factor will be in the header, but since we\n            // don't have the header yet, we just guess. The consequence of\n            // getting this wrong isn't terminal, it only means we may be\n            // fetching slightly more than we need or that we need to make an\n            // extra request later.\n            const assumedBranchingFactor = DEFAULT_NODE_SIZE;\n\n            // NOTE: each layer is exponentially larger\n            const prefetchedLayers = 3;\n\n            let result = 0;\n            let i: number;\n            for (i = 0; i < prefetchedLayers; i++) {\n                const layer_width = assumedBranchingFactor ** i * NODE_ITEM_BYTE_LEN;\n                result += layer_width;\n            }\n            return result;\n        })();\n\n        const minReqLength = assumedHeaderLength + assumedIndexLength;\n        console.debug(\n            `fetching header. minReqLength: ${minReqLength} (assumedHeaderLength: ${assumedHeaderLength}, assumedIndexLength: ${assumedIndexLength})`,\n        );\n\n        {\n            const bytes = new Uint8Array(await headerClient.getRange(0, 8, minReqLength, 'header'));\n            if (!bytes.subarray(0, 3).every((v, i) => magicbytes[i] === v)) {\n                console.error(`bytes: ${bytes} != ${magicbytes}`);\n                throw new Error('Not a FlatGeobuf file');\n            }\n            console.debug('magic bytes look good');\n        }\n\n        let headerLength: number;\n        {\n            const bytes = await headerClient.getRange(8, 4, minReqLength, 'header');\n            headerLength = new DataView(bytes).getUint32(0, true);\n            const HEADER_MAX_BUFFER_SIZE = 1048576 * 10;\n            if (headerLength > HEADER_MAX_BUFFER_SIZE || headerLength < 8) {\n                // minimum size check avoids panic in FlatBuffers header decoding\n                throw new Error('Invalid header size');\n            }\n            console.debug(`headerLength: ${headerLength}`);\n        }\n\n        const bytes = await headerClient.getRange(12, headerLength, minReqLength, 'header');\n        const bb = new flatbuffers.ByteBuffer(new Uint8Array(bytes));\n        const header = fromByteBuffer(bb);\n\n        if (header.indexNodeSize === 0) throw new Error('No index found, cannot read features filtered by bbox');\n\n        const indexLength = calcTreeSize(header.featuresCount, header.indexNodeSize);\n\n        console.debug('completed: opening http reader');\n        return new HttpReader(headerClient, header, headerLength, indexLength, nocache, headers);\n    }\n\n    async *selectBbox(rect: Rect): AsyncGenerator<FeatureWithId, void, unknown> {\n        // Read R-Tree index and build filter for features within bbox\n        const lengthBeforeTree = this.lengthBeforeTree();\n\n        const bufferedClient = this.headerClient;\n        const readNode = async (offsetIntoTree: number, size: number): Promise<ArrayBuffer> => {\n            const minReqLength = 0;\n            return bufferedClient.getRange(lengthBeforeTree + offsetIntoTree, size, minReqLength, 'index');\n        };\n\n        const batches: [number, number, number][][] = [];\n        let currentBatch: [number, number, number][] = [];\n        for await (const searchResult of streamSearch(\n            this.header.featuresCount,\n            this.header.indexNodeSize,\n            rect,\n            readNode,\n        )) {\n            const [featureOffset, featureIdx] = searchResult;\n            let [, , featureLength] = searchResult;\n            if (!featureLength) {\n                console.debug('final feature');\n                // Normally we get the feature length by subtracting between\n                // adjacent nodes from the index, which we can't do for the\n                // _very_ last feature in a dataset.\n                //\n                // We could *guess* the size, but we'd risk overshooting the length,\n                // which will cause some webservers to return HTTP 416: Unsatisfiable range\n                //\n                // So instead we fetch only the final features byte length, stored in the\n                // first 4 bytes.\n                featureLength = 4;\n            }\n\n            if (currentBatch.length === 0) {\n                currentBatch.push([featureOffset, featureLength, featureIdx]);\n                continue;\n            }\n\n            const prevFeature = currentBatch[currentBatch.length - 1];\n            const gap = featureOffset - (prevFeature[0] + prevFeature[1]);\n            if (gap > Config.global.extraRequestThreshold()) {\n                console.debug(`Pushing new feature batch, since gap ${gap} was too large`);\n                batches.push(currentBatch);\n                currentBatch = [];\n            }\n\n            currentBatch.push([featureOffset, featureLength, featureIdx]);\n        }\n        this.headerClient.logUsage('header+index');\n        if (currentBatch.length > 0) {\n            batches.push(currentBatch);\n        }\n\n        const promises: AsyncGenerator<FeatureWithId, void, unknown>[] = batches.flatMap(\n            (batch: [number, number, number][]) => this.readFeatureBatch(batch, this.nocache),\n        );\n\n        // Fetch all batches concurrently, yielding features as they become\n        // available, meaning the results may be intermixed.\n        yield* Repeater.merge(promises);\n    }\n\n    lengthBeforeTree(): number {\n        // FGB Layout is: [magicbytes (fixed), headerLength (i32), header (variable), Tree (variable), Features (variable)]\n        return magicbytes.length + SIZE_PREFIX_LEN + this.headerLength;\n    }\n\n    lengthBeforeFeatures(): number {\n        return this.lengthBeforeTree() + this.indexLength;\n    }\n\n    buildFeatureClient(nocache: boolean): BufferedHttpRangeClient {\n        return new BufferedHttpRangeClient(this.headerClient.httpClient, nocache, this.headers);\n    }\n\n    /**\n     * Fetch a batch of features in a single request, yielding each Feature\n     *\n     * `batch`: [offset, length] of features in the batch\n     */\n    async *readFeatureBatch(\n        batch: [number, number, number][],\n        nocache: boolean,\n    ): AsyncGenerator<FeatureWithId, void, unknown> {\n        const [firstFeatureOffset] = batch[0];\n        const [lastFeatureOffset, lastFeatureLength] = batch[batch.length - 1];\n\n        const batchStart = firstFeatureOffset;\n        const batchEnd = lastFeatureOffset + lastFeatureLength;\n        const batchSize = batchEnd - batchStart;\n\n        // A new feature client is needed for each batch to own the underlying buffer as features are yielded.\n        const featureClient = this.buildFeatureClient(nocache);\n\n        let minFeatureReqLength = batchSize;\n        for (const [featureOffset, , featureIdx] of batch) {\n            const feature = await this.readFeature(featureClient, featureOffset, minFeatureReqLength);\n            yield { id: featureIdx, feature };\n            // Only set minFeatureReqLength for the first request.\n            //\n            // This should only affect a batch that contains the final feature, otherwise\n            // we've calculated `batchSize` to get all the data we need for the batch.\n            // For the very final feature in a dataset, we don't know it's length, so we\n            // will end up executing an extra request for that batch.\n            minFeatureReqLength = 0;\n        }\n        featureClient.logUsage('feature');\n    }\n\n    async readFeature(\n        featureClient: BufferedHttpRangeClient,\n        featureOffset: number,\n        minFeatureReqLength: number,\n    ): Promise<Feature> {\n        const offset = featureOffset + this.lengthBeforeFeatures();\n\n        let featureLength: number;\n        {\n            const bytes = await featureClient.getRange(offset, 4, minFeatureReqLength, 'feature length');\n            featureLength = new DataView(bytes).getUint32(0, true);\n        }\n\n        const byteBuffer = await featureClient.getRange(offset + 4, featureLength, minFeatureReqLength, 'feature data');\n        const bytes = new Uint8Array(byteBuffer);\n        const bytesAligned = new Uint8Array(featureLength + SIZE_PREFIX_LEN);\n        bytesAligned.set(bytes, SIZE_PREFIX_LEN);\n        const bb = new flatbuffers.ByteBuffer(bytesAligned);\n        bb.setPosition(SIZE_PREFIX_LEN);\n        return Feature.getRootAsFeature(bb);\n    }\n}\n\nclass BufferedHttpRangeClient {\n    httpClient: HttpRangeClient;\n    bytesEverUsed = 0;\n    bytesEverFetched = 0;\n\n    private buffer: ArrayBuffer = new ArrayBuffer(0);\n\n    // Byte offset of `buffer` with respect to the beginning of the file being\n    // buffered\n    private head = 0;\n\n    constructor(source: string | HttpRangeClient, nocache: boolean, headers: HeadersInit = {}) {\n        if (typeof source === 'string') {\n            this.httpClient = new HttpRangeClient(source, nocache, headers);\n        } else if (source instanceof HttpRangeClient) {\n            this.httpClient = source;\n        } else {\n            throw new Error('Unknown source');\n        }\n    }\n\n    async getRange(start: number, length: number, minReqLength: number, purpose: string): Promise<ArrayBuffer> {\n        this.bytesEverUsed += length;\n\n        const start_i = start - this.head;\n        const end_i = start_i + length;\n        if (start_i >= 0 && end_i <= this.buffer.byteLength) {\n            return this.buffer.slice(start_i, end_i);\n        }\n\n        const lengthToFetch = Math.max(length, minReqLength);\n\n        this.bytesEverFetched += lengthToFetch;\n        console.debug(`requesting for new Range: ${start}-${start + lengthToFetch - 1}`);\n        this.buffer = await this.httpClient.getRange(start, lengthToFetch, purpose);\n        this.head = start;\n\n        return this.buffer.slice(0, length);\n    }\n\n    logUsage(purpose: string): void {\n        const category = purpose.split(' ')[0];\n        const used = this.bytesEverUsed;\n        const requested = this.bytesEverFetched;\n        const efficiency = ((100.0 * used) / requested).toFixed(2);\n\n        console.debug(`${category} bytes used/requested: ${used} / ${requested} = ${efficiency}%`);\n    }\n}\n\nclass HttpRangeClient {\n    url: string;\n    nocache: boolean;\n    headers: HeadersInit;\n    requestsEverMade = 0;\n    bytesEverRequested = 0;\n\n    constructor(url: string, nocache: boolean, headers: HeadersInit = {}) {\n        this.url = url;\n        this.nocache = nocache;\n        this.headers = headers;\n    }\n\n    async getRange(begin: number, length: number, purpose: string): Promise<ArrayBuffer> {\n        this.requestsEverMade += 1;\n        this.bytesEverRequested += length;\n\n        const range = `bytes=${begin}-${begin + length - 1}`;\n        console.debug(\n            `request: #${this.requestsEverMade}, purpose: ${purpose}), bytes: (this_request: ${length}, ever: ${this.bytesEverRequested}), Range: ${range}`,\n        );\n\n        // TODO: better parallelize requests on Chrome\n        //\n        // Safari and Firefox have no issue performing Range requests\n        // for a resource in parallel, but Chrome will stall a\n        // subsequent request to the resource until it's received the\n        // response headers of the prior request. So, it still allows\n        // some limited parallelization, but it's not ideal.\n        //\n        // This is seemingly an artifact of how Chrome manages caching\n        // and it might differ between platforms. We could work around it\n        // by setting the request header:\n        //\n        //      'Cache-Control': 'no-cache, no-store'\n        //\n        // This allows requests to be fully parallelized in Chrome, but\n        // then Chrome won't cache the response, so it seems not a\n        // great trade-off.\n        //\n        // Another work around would be to make each Range request for\n        // a separate URL by appending something like\n        // `?cache_buster=<range>` to the URL, but then Chrome will\n        // require an additional CORS preflight OPTIONS requests per\n        // Range, which is also not a great trade-off.\n        //\n        // See:\n        // https://bugs.chromium.org/p/chromium/issues/detail?id=969828&q=concurrent%20range%20requests&can=2\n        // https://stackoverflow.com/questions/27513994/chrome-stalls-when-making-multiple-requests-to-same-resource\n        const headers = new Headers(this.headers);\n        headers.set('Range', range);\n        if (this.nocache) headers.set('Cache-Control', 'no-cache, no-store');\n\n        const response = await fetch(this.url, { headers });\n        const arrayBuffer = await response.arrayBuffer();\n        return arrayBuffer;\n    }\n}\n"],"names":["Repeater","flatbuffers","Config","magicbytes","SIZE_PREFIX_LEN","Feature","fromByteBuffer","calcTreeSize","DEFAULT_NODE_SIZE","NODE_ITEM_BYTE_LEN","streamSearch","HttpReader","headerClient","header","headerLength","indexLength","nocache","headers","open","url","BufferedHttpRangeClient","minReqLength","assumedHeaderLength","i","result","assumedBranchingFactor","bytes","Uint8Array","getRange","subarray","every","v","Error","DataView","getUint32","ByteBuffer","indexNodeSize","featuresCount","selectBbox","rect","lengthBeforeTree","bufferedClient","readNode","offsetIntoTree","size","batches","currentBatch","searchResult","featureOffset","featureIdx","featureLength","length","push","prevFeature","global","extraRequestThreshold","logUsage","promises","flatMap","batch","readFeatureBatch","merge","lengthBeforeFeatures","buildFeatureClient","httpClient","firstFeatureOffset","lastFeatureOffset","lastFeatureLength","featureClient","minFeatureReqLength","batchEnd","feature","readFeature","id","offset","bytesAligned","set","bb","setPosition","getRootAsFeature","bytesEverUsed","bytesEverFetched","buffer","ArrayBuffer","head","source","HttpRangeClient","start","purpose","start_i","end_i","byteLength","slice","lengthToFetch","Math","max","split","toFixed","requestsEverMade","bytesEverRequested","begin","range","Headers","response","fetch","arrayBuffer"],"mappings":"AAAA,OAASA,YAAAA,CAAQ,KAAQ,sBAAuB,AAChD,WAAYC,MAAiB,aAAc,AAE3C,QAAOC,MAAY,aAAc,AACjC,QAASC,cAAAA,CAAU,CAAEC,mBAAAA,CAAe,KAAQ,gBAAiB,AAC7D,QAASC,WAAAA,CAAO,KAAQ,0BAA2B,AAEnD,QAASC,kBAAAA,CAAc,KAAQ,kBAAmB,AAClD,QAASC,gBAAAA,CAAY,CAAEC,qBAAAA,CAAiB,CAAEC,sBAAAA,CAAkB,CAAaC,gBAAAA,CAAY,KAAQ,kBAAmB,AAOhH,QAAO,MAAMC,WACT,AAAQC,YAAsC,AAC9C,CAAOC,MAAmB,AAC1B,CAAQC,YAAqB,AAC7B,CAAQC,WAAoB,AAC5B,CAAQC,OAAiB,AACzB,CAAQC,OAAqB,AAE7B,aACIL,CAAqC,CACrCC,CAAkB,CAClBC,CAAoB,CACpBC,CAAmB,CACnBC,CAAgB,CAChBC,EAAuB,CAAC,CAAC,CAC3B,CACE,IAAI,CAACL,YAAY,CAAGA,EACpB,IAAI,CAACC,MAAM,CAAGA,EACd,IAAI,CAACC,YAAY,CAAGA,EACpB,IAAI,CAACC,WAAW,CAAGA,EACnB,IAAI,CAACC,OAAO,CAAGA,EACf,IAAI,CAACC,OAAO,CAAGA,CACnB,CAKA,aAAaC,KAAKC,CAAW,CAAEH,CAAgB,CAAEC,EAAuB,CAAC,CAAC,CAAuB,CAM7F,IAsCIH,EAtCEF,EAAe,IAAIQ,EAAwBD,EAAKH,EAASC,GAwBzDI,EAAeC,AA1BO,KAMD,AAAC,CAAA,KAWxB,IACIC,EADAC,EAAS,EAEb,IAAKD,EAAI,EAAGA,EAJa,EAISA,IAE9BC,GADoBC,AAROjB,GAQmBe,EAAId,EAGtD,OAAOe,CACX,CAAA,IASI,GAAI,CAACE,AADS,IAAIC,WAAW,MAAMf,EAAagB,QAAQ,CAAC,EAAG,EAAGP,EAAc,WAClEQ,QAAQ,CAAC,EAAG,GAAGC,KAAK,CAAC,CAACC,EAAGR,IAAMpB,CAAU,CAACoB,EAAE,GAAKQ,GAExD,MAAM,AAAIC,MAAM,yBAUpB,GAAIlB,AAFJA,CAAAA,EAAe,IAAImB,SADL,MAAMrB,EAAagB,QAAQ,CAAC,EAAG,EAAGP,EAAc,WAC3Ba,SAAS,CAAC,EAAG,CAAA,EAAI,EACrB,UACcpB,EAAe,EAExD,MAAM,AAAIkB,MAAM,uBAKxB,IAAMN,EAAQ,MAAMd,EAAagB,QAAQ,CAAC,GAAId,EAAcO,EAAc,UAEpER,EAASP,EADJ,IAAIL,EAAYkC,UAAU,CAAC,IAAIR,WAAWD,KAGrD,GAAIb,AAAyB,IAAzBA,EAAOuB,aAAa,CAAQ,MAAM,AAAIJ,MAAM,yDAEhD,IAAMjB,EAAcR,EAAaM,EAAOwB,aAAa,CAAExB,EAAOuB,aAAa,EAG3E,OAAO,IAAIzB,WAAWC,EAAcC,EAAQC,EAAcC,EAAaC,EAASC,EACpF,CAEA,OAAOqB,WAAWC,CAAU,CAAgD,CAExE,IAAMC,EAAmB,IAAI,CAACA,gBAAgB,GAExCC,EAAiB,IAAI,CAAC7B,YAAY,CAClC8B,EAAW,MAAOC,EAAwBC,IAErCH,EAAeb,QAAQ,CAACY,EAAmBG,EAAgBC,EAD7C,EACiE,SAGpFC,EAAwC,EAAE,CAC5CC,EAA2C,EAAE,CACjD,UAAW,IAAMC,KAAgBrC,EAC7B,IAAI,CAACG,MAAM,CAACwB,aAAa,CACzB,IAAI,CAACxB,MAAM,CAACuB,aAAa,CACzBG,EACAG,GACD,CACC,GAAM,CAACM,EAAeC,EAAW,CAAGF,EAChC,GAAKG,EAAc,CAAGH,EAe1B,GAdI,AAACG,GAWDA,CAAAA,EAAgB,CAAA,EAGhBJ,AAAwB,IAAxBA,EAAaK,MAAM,CAAQ,CAC3BL,EAAaM,IAAI,CAAC,CAACJ,EAAeE,EAAeD,EAAW,EAC5D,QACJ,CAEA,IAAMI,EAAcP,CAAY,CAACA,EAAaK,MAAM,CAAG,EAAE,CAC7CH,EAAiBK,CAAAA,CAAW,CAAC,EAAE,CAAGA,CAAW,CAAC,EAAE,AAAD,EACjDnD,EAAOoD,MAAM,CAACC,qBAAqB,KAEzCV,EAAQO,IAAI,CAACN,GACbA,EAAe,EAAE,EAGrBA,EAAaM,IAAI,CAAC,CAACJ,EAAeE,EAAeD,EAAW,CAChE,CACA,IAAI,CAACrC,YAAY,CAAC4C,QAAQ,CAAC,gBACvBV,EAAaK,MAAM,CAAG,GACtBN,EAAQO,IAAI,CAACN,GAGjB,IAAMW,EAA2DZ,EAAQa,OAAO,CAC5E,AAACC,GAAsC,IAAI,CAACC,gBAAgB,CAACD,EAAO,IAAI,CAAC3C,OAAO,EAKpF,OAAOhB,EAAS6D,KAAK,CAACJ,EAC1B,CAEAjB,kBAA2B,CAEvB,OAAOrC,EAAWgD,MAAM,CAAG/C,EAAkB,IAAI,CAACU,YAAY,AAClE,CAEAgD,sBAA+B,CAC3B,OAAO,IAAI,CAACtB,gBAAgB,GAAK,IAAI,CAACzB,WAAW,AACrD,CAEAgD,mBAAmB/C,CAAgB,CAA2B,CAC1D,OAAO,IAAII,EAAwB,IAAI,CAACR,YAAY,CAACoD,UAAU,CAAEhD,EAAS,IAAI,CAACC,OAAO,CAC1F,CAOA,OAAO2C,iBACHD,CAAiC,CACjC3C,CAAgB,CAC4B,CAC5C,GAAM,CAACiD,EAAmB,CAAGN,CAAK,CAAC,EAAE,CAC/B,CAACO,EAAmBC,EAAkB,CAAGR,CAAK,CAACA,EAAMR,MAAM,CAAG,EAAE,CAOhEiB,EAAgB,IAAI,CAACL,kBAAkB,CAAC/C,GAE1CqD,EALcC,AADDJ,EAAoBC,EADlBF,EAQnB,IAAK,GAAM,CAACjB,GAAiBC,EAAW,GAAIU,EAAO,CAC/C,IAAMY,EAAU,MAAM,IAAI,CAACC,WAAW,CAACJ,EAAepB,EAAeqB,EACrE,MAAM,CAAEI,GAAIxB,EAAYsB,QAAAA,CAAQ,EAOhCF,EAAsB,CAC1B,CACAD,EAAcZ,QAAQ,CAAC,UAC3B,CAEA,MAAMgB,YACFJ,CAAsC,CACtCpB,CAAqB,CACrBqB,CAA2B,CACX,CAChB,IAEInB,EAFEwB,EAAS1B,EAAgB,IAAI,CAACc,oBAAoB,GAKpDZ,EAAgB,IAAIjB,SADN,MAAMmC,EAAcxC,QAAQ,CAAC8C,EAAQ,EAAGL,EAAqB,mBACvCnC,SAAS,CAAC,EAAG,CAAA,GAIrD,IAAMR,EAAQ,IAAIC,WADC,MAAMyC,EAAcxC,QAAQ,CAAC8C,EAAS,EAAGxB,EAAemB,EAAqB,iBAE1FM,EAAe,IAAIhD,WAAWuB,EAAgB9C,GACpDuE,EAAaC,GAAG,CAAClD,EAAOtB,GACxB,IAAMyE,EAAK,IAAI5E,EAAYkC,UAAU,CAACwC,GAEtC,OADAE,EAAGC,WAAW,CAAC1E,GACRC,EAAQ0E,gBAAgB,CAACF,EACpC,CACJ,CAEA,MAAMzD,EACF4C,UAA4B,AAC5BgB,CAAAA,cAAgB,CAAE,AAClBC,CAAAA,iBAAmB,CAAE,AAErB,CAAQC,OAAsB,IAAIC,YAAY,EAAG,AAIjD,CAAQC,KAAO,CAAE,AAEjB,aAAYC,CAAgC,CAAErE,CAAgB,CAAEC,EAAuB,CAAC,CAAC,CAAE,CACvF,GAAI,AAAkB,UAAlB,OAAOoE,EACP,IAAI,CAACrB,UAAU,CAAG,IAAIsB,EAAgBD,EAAQrE,EAASC,QACpD,GAAIoE,aAAkBC,EACzB,IAAI,CAACtB,UAAU,CAAGqB,OAElB,MAAM,AAAIrD,MAAM,iBAExB,CAEA,MAAMJ,SAAS2D,CAAa,CAAEpC,CAAc,CAAE9B,CAAoB,CAAEmE,CAAe,CAAwB,CACvG,IAAI,CAACR,aAAa,EAAI7B,EAEtB,IAAMsC,EAAUF,EAAQ,IAAI,CAACH,IAAI,CAC3BM,EAAQD,EAAUtC,EACxB,GAAIsC,GAAW,GAAKC,GAAS,IAAI,CAACR,MAAM,CAACS,UAAU,CAC/C,OAAO,IAAI,CAACT,MAAM,CAACU,KAAK,CAACH,EAASC,GAGtC,IAAMG,EAAgBC,KAAKC,GAAG,CAAC5C,EAAQ9B,GAOvC,OALA,IAAI,CAAC4D,gBAAgB,EAAIY,EAEzB,IAAI,CAACX,MAAM,CAAG,MAAM,IAAI,CAAClB,UAAU,CAACpC,QAAQ,CAAC2D,EAAOM,EAAeL,GACnE,IAAI,CAACJ,IAAI,CAAGG,EAEL,IAAI,CAACL,MAAM,CAACU,KAAK,CAAC,EAAGzC,EAChC,CAEAK,SAASgC,CAAe,CAAQ,CACXA,EAAQQ,KAAK,CAAC,IAAI,CAAC,EAAE,CAGnB,AAAC,CAAA,AAAC,IAFR,IAAI,CAAChB,aAAa,CACb,IAAI,CAACC,gBAAgB,AACM,EAAGgB,OAAO,CAAC,EAG5D,CACJ,CAEA,MAAMX,EACFnE,GAAY,AACZH,CAAAA,OAAiB,AACjBC,CAAAA,OAAqB,AACrBiF,CAAAA,iBAAmB,CAAE,AACrBC,CAAAA,mBAAqB,CAAE,AAEvB,aAAYhF,CAAW,CAAEH,CAAgB,CAAEC,EAAuB,CAAC,CAAC,CAAE,CAClE,IAAI,CAACE,GAAG,CAAGA,EACX,IAAI,CAACH,OAAO,CAAGA,EACf,IAAI,CAACC,OAAO,CAAGA,CACnB,CAEA,MAAMW,SAASwE,CAAa,CAAEjD,CAAc,CAAEqC,CAAe,CAAwB,CACjF,IAAI,CAACU,gBAAgB,EAAI,EACzB,IAAI,CAACC,kBAAkB,EAAIhD,EAE3B,IAAMkD,EAAQ,CAAC,MAAM,EAAED,EAAM,CAAC,EAAEA,EAAQjD,EAAS,EAAE,CAAC,CAgC9ClC,EAAU,IAAIqF,QAAQ,IAAI,CAACrF,OAAO,EACxCA,EAAQ2D,GAAG,CAAC,QAASyB,GACjB,IAAI,CAACrF,OAAO,EAAEC,EAAQ2D,GAAG,CAAC,gBAAiB,sBAE/C,IAAM2B,EAAW,MAAMC,MAAM,IAAI,CAACrF,GAAG,CAAE,CAAEF,QAAAA,CAAQ,GAEjD,OADoB,MAAMsF,EAASE,WAAW,EAElD,CACJ"}